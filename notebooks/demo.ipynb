{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo music query\n",
    "\n",
    "We perform the following in order to generate recommendation.\n",
    "\n",
    "1. Load an embeddings and cluster model.\n",
    "2. Query by specifying song title and any metadata to condition.\n",
    "3. Get lyrics through an API.\n",
    "    - First with [this API](http://www.chartlyrics.com/api.aspx), as it's free and does not require an API key.\n",
    "    - Otherwise fall back on [this API](https://github.com/johnwmillr/LyricsGenius) to access Genius. **Note you will need an API key which can create [here](https://genius.com/api-clients).**\n",
    "4. Get Spotify acoustic features and metadata with [this API](https://spotipy.readthedocs.io/en/2.19.0/). **Note you will need a client ID and secret key which can create [here](https://developer.spotify.com).**\n",
    "5. Return top K recommendations by:\n",
    "    - Computing embedding.\n",
    "    - Identifying corresponding cluster.\n",
    "    - Subset based on query.\n",
    "    \n",
    "First some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from pprint import pprint\n",
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def get_token(token_name, token_path=\"tokens.json\"):\n",
    "    TOKEN = None\n",
    "    if os.environ.get(token_name):\n",
    "        TOKEN = os.environ.get(token_name)\n",
    "    elif os.path.isfile(token_path):\n",
    "        f = open(token_path)\n",
    "        data = json.loads(f.read())\n",
    "        TOKEN = data[token_name]\n",
    "    else:\n",
    "        assert TOKEN is not None, f\"No value for {token_name}.\"\n",
    "    return TOKEN\n",
    "\n",
    "\n",
    "def standardize_lyrics(lyrics, i=0, verbose=False):\n",
    "    if verbose:\n",
    "        print(i)\n",
    "    if lyrics is np.nan or len(lyrics) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # remove new lines\n",
    "    clean = lyrics.replace(\"\\\\n\\\\n\", \". \").replace(\"\\\\n\", \". \").replace(\"\\\\\", \"\")\n",
    "    \n",
    "    # remove square brackets around lyrics\n",
    "    # if possible, extract chorus, pre-chorus, post-chorus, bridge, verses\n",
    "    song_parts = [\"Chorus\", \"Pre-Chorus\", \"Post-Chorus\", \"Bridge\", \"Verse 1\", \"Verse 2\", \"Verse 3\", \"Verse 4\"]\n",
    "    if verbose:\n",
    "        for part in song_parts:\n",
    "            text = find_between(clean, f\"[{part}]. \", \"[\")\n",
    "            if len(text):\n",
    "                print(f\"\\n{part} : {text}\")\n",
    "    \n",
    "    for part in song_parts:\n",
    "        clean = clean.replace(f\"[{part}]. \", \"\")\n",
    "        \n",
    "        \n",
    "    # remove anything else in square brackets\n",
    "    clean = re.sub(\"[\\[].*?[\\]]\", \"\", clean)\n",
    "    \n",
    "    # clean up\n",
    "    clean = clean.replace('\"', \"\")\n",
    "    try:\n",
    "        while clean[0] == \".\" or clean[0] == \" \" or clean[0] == \"'\":\n",
    "            clean = clean[1:]\n",
    "    except:\n",
    "        return np.nan\n",
    "    try:\n",
    "        if clean[-1] == \"'\":\n",
    "            clean = clean[:-1]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    clean = clean.strip().replace(\"\\n\", \" \")\n",
    "        \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) load encoder and clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model hub or local path\n",
    "# TODO detect when local path and need to remove classification head\n",
    "embeddings_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "clusters_path  = \"\"\n",
    "\n",
    "\n",
    "if not os.path.isfile(embeddings_model):\n",
    "    # coming from model hub\n",
    "    model = SentenceTransformer(embeddings_model)\n",
    "else:\n",
    "    raise ValueError(\"strip of classification head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) specify query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_title = \"car radio\"\n",
    "# artist = \"twenty one pilots\"\n",
    "song_title = \"we are the champions\"\n",
    "artist = \"queen\"\n",
    "genre = \"hip-hop/rap\"    # get available genres from Pandas dataframe\n",
    "danceability = 1   # positive for more, 0 for no preference, negative for less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) get lyrics\n",
    "\n",
    "- http://www.chartlyrics.com/api.aspx\n",
    "- https://github.com/johnwmillr/LyricsGenius\n",
    "\n",
    "For last approach, you need an [API token](https://genius.com/api-clients) and add it to your environment variables:\n",
    "```\n",
    "export GENIUS_ACCESS_TOKEN=\"my_access_token_here\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENIUS_ACCESS_TOKEN = get_token(\"GENIUS_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've paid my dues Time after time I've done my sentence But committed no crime  And bad mistakes I've made a few I've had my share of sand kicked in my face But I've come through And we mean to go on and on and on  We are the champions - my friends And we'll keep on fighting - till the end We are the champions We are the champions No time for losers 'Cause we are the champions - of the world  I've taken my bows And my curtain calls You brought me fame and fortune and everything that goes with it I thank you all  But it's been no bed of roses No pleasure cruise I consider it a challenge before the whole human race And I ain't gonna lose And I need to go on and on and on  We are the champions - my friends And we'll keep on fighting - till the end We are the champions We are the champions No time for losers 'Cause we are the champions - of the world  We are the champions - my friends And we'll keep on fighting - till the end We are the champions We are the champions No time for losers 'Cause we are the champions\n"
     ]
    }
   ],
   "source": [
    "start_url = f\"http://api.chartlyrics.com/apiv1.asmx/SearchLyricDirect?artist={artist}&song={song_title}\"\n",
    "url = start_url.replace(\" \",\"%20\")\n",
    "contents = urllib.request.urlopen(url).read()\n",
    "root = ET.fromstring(contents.decode(\"utf-8\"))\n",
    "for child in root:\n",
    "    tag = child.tag.split(\"}\")[1]\n",
    "    if tag == \"Lyric\":\n",
    "        lyrics = child.text\n",
    "if lyrics is not None:\n",
    "    lyrics = lyrics.strip().replace(\"\\n\", \" \")\n",
    "elif os.environ.get('GENIUS_ACCESS_TOKEN'):\n",
    "    # use Genius API\n",
    "    print(\"Using Genius...\")\n",
    "    genius = lyricsgenius.Genius(GENIUS_ACCESS_TOKEN)\n",
    "    song = genius.search_song(song_title, artist)\n",
    "    lyrics = standardize_lyrics(song.lyrics)\n",
    "    lyrics = ' '.join(lyrics.split(' ')[:-1])[:-13]   # remove last part Genius adds\n",
    "else:\n",
    "    raise ValueError(\"Could not find song.\")\n",
    "    \n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) get spotipy metadata and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "be sure to have credentials from [here](https://developer.spotify.com) and save them as environment variables.\n",
    "```\n",
    "export SPOTIPY_CLIENT_ID='your-spotify-client-id'\n",
    "export SPOTIPY_CLIENT_SECRET='your-spotify-client-secret'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTIPY_CLIENT_ID = get_token(\"SPOTIPY_CLIENT_ID\")\n",
    "SPOTIPY_CLIENT_SECRET = get_token(\"SPOTIPY_CLIENT_SECRET\")\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We Are The Champions - Remastered 2011 by ['Queen']\n"
     ]
    }
   ],
   "source": [
    "# search for song, https://developer.spotify.com/documentation/web-api/reference/#/operations/search\n",
    "query = f\"track:{song_title}\"\n",
    "if artist is not None:\n",
    "    query += f\" artist:{artist}\"\n",
    "res = sp.search(q=query, type='track')\n",
    "\n",
    "# take top entry\n",
    "_id = 0\n",
    "rx_song = res[\"tracks\"][\"items\"][0][\"name\"]\n",
    "rx_artists = [artist[\"name\"] for artist in res[\"tracks\"][\"items\"][0][\"artists\"]]\n",
    "print(f\"{rx_song} by {rx_artists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acousticness': 0.378,\n",
      " 'danceability': 0.268,\n",
      " 'energy': 0.459,\n",
      " 'instrumentalness': 0,\n",
      " 'liveness': 0.119,\n",
      " 'loudness': -6.948,\n",
      " 'mode': 0,\n",
      " 'popularity': 66,\n",
      " 'release_year': 1977,\n",
      " 'speechiness': 0.0346,\n",
      " 'tempo': 64.223,\n",
      " 'valence': 0.172}\n"
     ]
    }
   ],
   "source": [
    "song_metadata = dict()\n",
    "song_metadata[\"release_year\"] = int(res[\"tracks\"][\"items\"][_id][\"album\"][\"release_date\"][:4])\n",
    "song_metadata[\"popularity\"] = res[\"tracks\"][\"items\"][_id][\"popularity\"]\n",
    "\n",
    "# get acoustic features\n",
    "acoustic_features = [\"mode\", \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"valence\", \"tempo\"]\n",
    "uri = res[\"tracks\"][\"items\"][_id][\"uri\"]\n",
    "feat_results = sp.audio_features(uri)[0]\n",
    "for _feat in acoustic_features:\n",
    "    song_metadata[_feat] = feat_results[_feat]\n",
    "pprint(song_metadata)\n",
    "\n",
    "# could probably also get genre metadata from this API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) return top K recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first compute embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "embedding = model.encode(lyrics)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify corresponding cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset based on query and give top K recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
