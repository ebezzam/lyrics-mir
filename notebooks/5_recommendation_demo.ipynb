{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo music query\n",
    "\n",
    "We perform the following in order to generate recommendation.\n",
    "\n",
    "1. Load an embeddings and cluster model.\n",
    "2. Query by specifying song title and any metadata to condition.\n",
    "3. Get lyrics through an API.\n",
    "    - First with [this API](http://www.chartlyrics.com/api.aspx), as it's free and does not require an API key.\n",
    "    - Otherwise fall back on [this API](https://github.com/johnwmillr/LyricsGenius) to access Genius. **Note you will need an API key which can create [here](https://genius.com/api-clients).**\n",
    "4. Get Spotify acoustic features and metadata with [this API](https://spotipy.readthedocs.io/en/2.19.0/). **Note you will need a client ID and secret key which can create [here](https://developer.spotify.com).**\n",
    "5. Return top K recommendations by:\n",
    "    - Computing embedding.\n",
    "    - Identifying corresponding cluster.\n",
    "    - Subset based on query.\n",
    "    \n",
    "First some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pprint import pprint\n",
    "import os\n",
    "import spotipy\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoConfig, AutoModel,AutoModelForPreTraining, AutoTokenizer\n",
    "\n",
    "\n",
    "def get_token(token_name, token_path=\"tokens.json\"):\n",
    "    TOKEN = None\n",
    "    if os.environ.get(token_name):\n",
    "        TOKEN = os.environ.get(token_name)\n",
    "    elif os.path.isfile(token_path):\n",
    "        f = open(token_path)\n",
    "        data = json.loads(f.read())\n",
    "        TOKEN = data[token_name]\n",
    "    else:\n",
    "        assert TOKEN is not None, f\"No value for {token_name}.\"\n",
    "    return TOKEN\n",
    "\n",
    "\n",
    "def standardize_lyrics(lyrics, i=0, verbose=False):\n",
    "    if verbose:\n",
    "        print(i)\n",
    "    if lyrics is np.nan or len(lyrics) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # remove new lines\n",
    "    clean = lyrics.replace(\"\\\\n\\\\n\", \". \").replace(\"\\\\n\", \". \").replace(\"\\\\\", \"\")\n",
    "    \n",
    "    # remove square brackets around lyrics\n",
    "    # if possible, extract chorus, pre-chorus, post-chorus, bridge, verses\n",
    "    song_parts = [\"Chorus\", \"Pre-Chorus\", \"Post-Chorus\", \"Bridge\", \"Verse 1\", \"Verse 2\", \"Verse 3\", \"Verse 4\"]\n",
    "    if verbose:\n",
    "        for part in song_parts:\n",
    "            text = find_between(clean, f\"[{part}]. \", \"[\")\n",
    "            if len(text):\n",
    "                print(f\"\\n{part} : {text}\")\n",
    "    \n",
    "    for part in song_parts:\n",
    "        clean = clean.replace(f\"[{part}]. \", \"\")\n",
    "        \n",
    "        \n",
    "    # remove anything else in square brackets\n",
    "    clean = re.sub(\"[\\[].*?[\\]]\", \"\", clean)\n",
    "    \n",
    "    # clean up\n",
    "    clean = clean.replace('\"', \"\")\n",
    "    try:\n",
    "        while clean[0] == \".\" or clean[0] == \" \" or clean[0] == \"'\":\n",
    "            clean = clean[1:]\n",
    "    except:\n",
    "        return np.nan\n",
    "    try:\n",
    "        if clean[-1] == \"'\":\n",
    "            clean = clean[:-1]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    clean = clean.strip().replace(\"\\n\", \" \")\n",
    "        \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) specify encoder and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model hub or local path\n",
    "embeddings_model = \"all-mpnet-base-v2\"\n",
    "embeddings_model = \"all-mpnet-base-v2-finetuned-genre_unfrozen_base-checkpoint-1735/checkpoint-1735\"\n",
    "n_clusters = 4\n",
    "affinity = \"cosine\"     # “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. If linkage is “ward”, only “euclidean” is accepted\n",
    "linkage = \"complete\"    # {‘ward’, ‘complete’, ‘average’, ‘single’}, default=’ward’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) specify query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_title = \"the lazy song\"\n",
    "artist = \"bruno mars\"\n",
    "# song_title = \"we are the champions\"\n",
    "# artist = \"queen\"\n",
    "genre = \"country\"    # ['dance pop', 'acoustic/folk', 'hip-hop/rap', 'pop', 'soul/disco', 'country', 'r&b', 'rock']\n",
    "danceability = 0   # positive for more, 0 for no preference, negative for less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) get lyrics\n",
    "\n",
    "- http://www.chartlyrics.com/api.aspx\n",
    "- https://github.com/johnwmillr/LyricsGenius\n",
    "\n",
    "For last approach, you need an [API token](https://genius.com/api-clients) and add it to your environment variables:\n",
    "```\n",
    "export GENIUS_ACCESS_TOKEN=\"my_access_token_here\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENIUS_ACCESS_TOKEN = get_token(\"GENIUS_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Genius...\n",
      "Searching for \"the lazy song\" by bruno mars...\n",
      "Done.\n",
      "Today, I don't feel like doing anything I just wanna lay in my bed Don't feel like picking up my phone So leave a message at the tone 'Cause today, I swear, I'm not doing anything   I'm gonna kick my feet up, then stare at the fan Turn the TV on, throw my hand in my pants Nobody's gon' tell me I can't, nah I'll be lounging on the couch, just chillin' in my Snuggie Click to MTV, so they can teach me how to dougie 'Cause in my castle, I'm the freaking man   Oh-oh, yes, I said it I said it, I said it, 'cause I can   Today, I don't feel like doing anything I just wanna lay in my bed Don't feel like picking up my phone So leave a message at the tone 'Cause today, I swear, I'm not doing anything Nothing at all (Woo-hoo, woo-hoo, ooh) Nothing at all (Woo-hoo, woo-hoo, ooh)  Tomorrow, I'll wake up, do some P90X Meet a really nice girl, have some really nice sex And she's gonna scream out, This is great! (Oh my God, this is great) Yeah, I might mess around and get my college degree I bet my old man will be so proud of me But sorry, pops, you'll just have to wait   Oh-oh, yes I said it I said it, I said it, 'cause I can   Today, I don't feel like doing anything I just wanna lay in my bed Don't feel like picking up my phone So leave a message at the tone 'Cause today, I swear, I'm not doing anything   No, I ain't gonna comb my hair 'Cause I ain't going anywhere No, no, no, no, no, no, no, no, no I'll just strut in my birthday suit And let everything hang loose Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah  Oh, today, I don't feel like doing anything I just wanna lay in my bed Don't feel like picking up my phone So leave a message at the tone 'Cause today, I swear, I'm not doing anything Nothing at all (Woo-hoo, woo-hoo, ooh) Nothing at all (Woo-hoo, woo-hoo, ooh) Nothing at al\n"
     ]
    }
   ],
   "source": [
    "start_url = f\"http://api.chartlyrics.com/apiv1.asmx/SearchLyricDirect?artist={artist}&song={song_title}\"\n",
    "url = start_url.replace(\" \",\"%20\")\n",
    "contents = urllib.request.urlopen(url).read()\n",
    "root = ET.fromstring(contents.decode(\"utf-8\"))\n",
    "for child in root:\n",
    "    tag = child.tag.split(\"}\")[1]\n",
    "    if tag == \"Lyric\":\n",
    "        lyrics = child.text\n",
    "if lyrics is not None:\n",
    "    lyrics = lyrics.strip().replace(\"\\n\", \" \")\n",
    "elif GENIUS_ACCESS_TOKEN:\n",
    "    # use Genius API\n",
    "    print(\"Using Genius...\")\n",
    "    genius = lyricsgenius.Genius(GENIUS_ACCESS_TOKEN)\n",
    "    song = genius.search_song(song_title, artist)\n",
    "    lyrics = standardize_lyrics(song.lyrics)\n",
    "    lyrics = ' '.join(lyrics.split(' ')[:-1])[:-13]   # remove last part Genius adds\n",
    "else:\n",
    "    raise ValueError(\"Could not find song.\")\n",
    "    \n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) get spotipy metadata and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "be sure to have credentials from [here](https://developer.spotify.com) and save them as environment variables.\n",
    "```\n",
    "export SPOTIPY_CLIENT_ID='your-spotify-client-id'\n",
    "export SPOTIPY_CLIENT_SECRET='your-spotify-client-secret'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTIPY_CLIENT_ID = get_token(\"SPOTIPY_CLIENT_ID\")\n",
    "SPOTIPY_CLIENT_SECRET = get_token(\"SPOTIPY_CLIENT_SECRET\")\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lazy Song by ['Bruno Mars']\n"
     ]
    }
   ],
   "source": [
    "# search for song, https://developer.spotify.com/documentation/web-api/reference/#/operations/search\n",
    "query = f\"track:{song_title}\"\n",
    "if artist is not None:\n",
    "    query += f\" artist:{artist}\"\n",
    "res = sp.search(q=query, type='track')\n",
    "\n",
    "# take top entry\n",
    "_id = 0\n",
    "rx_song = res[\"tracks\"][\"items\"][0][\"name\"]\n",
    "rx_artists = [artist[\"name\"] for artist in res[\"tracks\"][\"items\"][0][\"artists\"]]\n",
    "print(f\"{rx_song} by {rx_artists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acousticness': 0.3,\n",
      " 'danceability': 0.794,\n",
      " 'energy': 0.711,\n",
      " 'instrumentalness': 0,\n",
      " 'liveness': 0.0955,\n",
      " 'loudness': -5.124,\n",
      " 'mode': 0,\n",
      " 'popularity': 74,\n",
      " 'release_year': 2010,\n",
      " 'speechiness': 0.0699,\n",
      " 'tempo': 174.915,\n",
      " 'valence': 0.955}\n"
     ]
    }
   ],
   "source": [
    "song_metadata = dict()\n",
    "song_metadata[\"release_year\"] = int(res[\"tracks\"][\"items\"][_id][\"album\"][\"release_date\"][:4])\n",
    "song_metadata[\"popularity\"] = res[\"tracks\"][\"items\"][_id][\"popularity\"]\n",
    "\n",
    "# get acoustic features\n",
    "acoustic_features = [\"mode\", \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"valence\", \"tempo\"]\n",
    "uri = res[\"tracks\"][\"items\"][_id][\"uri\"]\n",
    "feat_results = sp.audio_features(uri)[0]\n",
    "for _feat in acoustic_features:\n",
    "    song_metadata[_feat] = feat_results[_feat]\n",
    "pprint(song_metadata)\n",
    "\n",
    "# could probably also get genre metadata from this API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) return top K recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first compute embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at all-mpnet-base-v2-finetuned-genre_unfrozen_base-checkpoint-1735/checkpoint-1735/pytorch_model.bin were not used when initializing MPNetModel: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing MPNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at all-mpnet-base-v2-finetuned-genre_unfrozen_base-checkpoint-1735/checkpoint-1735/pytorch_model.bin and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(embeddings_model):\n",
    "    # coming from model hub\n",
    "    model = SentenceTransformer(embeddings_model)\n",
    "    query_embed = model.encode(lyrics)\n",
    "else:\n",
    "    # local model\n",
    "    config = AutoConfig.from_pretrained(f'{embeddings_model}/config.json')\n",
    "    model = AutoModel.from_config(config)\n",
    "    model = AutoModel.from_pretrained(f'{embeddings_model}/pytorch_model.bin',config=config)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(embeddings_model, use_fast=True)\n",
    "    \n",
    "    # TODO : simpler for a single lyric?\n",
    "    tokens = tokenizer.batch_encode_plus(\n",
    "        [lyrics],\n",
    "        max_length = 512,\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    embed = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len([lyrics]))):\n",
    "            tkin = tokens['input_ids'][i:i+1]\n",
    "            tkam = tokens['attention_mask'][i:i+1]\n",
    "\n",
    "            tkin = torch.tensor(tkin).cuda()\n",
    "            tkam = torch.tensor(tkam).cuda()\n",
    "\n",
    "            out = model(tkin,tkam)['last_hidden_state']\n",
    "            out = out.mean(1).cpu().numpy()\n",
    "\n",
    "            embed.append(out)\n",
    "    query_embed = embed[0][0]\n",
    "\n",
    "print(query_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify corresponding cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering/all-mpnet-base-v2-finetuned-genre_unfrozen_base-checkpoint-1735_4clusters_affinity=cosine_linkage=complete.npy\n",
      "[[0.5367125  0.7559653  0.72158474 0.5945208 ]]\n",
      "assigned cluster : 0\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(embeddings_model):\n",
    "    clustering_fp = os.path.split(embeddings_model)[0]\n",
    "else:\n",
    "    clustering_fp = embeddings_model\n",
    "clustering_fp += f\"_{n_clusters}clusters_affinity={affinity}_linkage={linkage}.npy\"\n",
    "clustering_fp = os.path.join(\"clustering\", clustering_fp)\n",
    "print(clustering_fp)\n",
    "\n",
    "# check if clustering already exists\n",
    "if os.path.isfile(clustering_fp):\n",
    "    cluster_assignment = np.load(clustering_fp)\n",
    "    \n",
    "else:\n",
    "    # compute with clustering notebook\n",
    "    raise ValueError(\"Cluster assignment not available.\")\n",
    "    \n",
    "    \n",
    "# compute centroids\n",
    "# -- load embeddings\n",
    "if os.path.isdir(embeddings_model):\n",
    "    embedding_fp = f\"{os.path.split(embeddings_model)[0]}_embeddings.pt\"\n",
    "else:\n",
    "    embedding_fp = f\"{embeddings_model}_embeddings.pt\"\n",
    "embedding_fp = os.path.join(\"embeddings\", embedding_fp)\n",
    "assert os.path.isfile(embedding_fp)\n",
    "corpus_embeddings = torch.load(embedding_fp)\n",
    "if torch.is_tensor(corpus_embeddings):\n",
    "    corpus_embeddings = corpus_embeddings.cpu().data.numpy()\n",
    "assert len(corpus_embeddings) == len(cluster_assignment)\n",
    "\n",
    "# -- average according to cluster assignment\n",
    "centroids = []\n",
    "for i in range(n_clusters):\n",
    "    inds = cluster_assignment == i\n",
    "    centroids.append(np.mean(corpus_embeddings[inds,:], axis=0))\n",
    "centroids = np.vstack(centroids)\n",
    "\n",
    "# identify closest cluster according to correct metric\n",
    "query_embed = query_embed / np.linalg.norm(query_embed, axis=-1, keepdims=True)\n",
    "\n",
    "if affinity == \"cosine\":\n",
    "    scores = cosine_distances(query_embed[np.newaxis, :], centroids)\n",
    "elif affinity == \"euclidean\":\n",
    "    scores = euclidean_distances(query_embed[np.newaxis, :], centroids)\n",
    "else:\n",
    "    raise ValueError\n",
    "assigned_cluster = np.argmin(scores)\n",
    "print(scores)\n",
    "print(\"assigned cluster :\", assigned_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset based on query and give top K recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset according to cluster\n",
    "inds = cluster_assignment == assigned_cluster\n",
    "embeddings_subset = corpus_embeddings[inds]\n",
    "dataset_path = \"df_clean_v4_14122021_py35.pkl\"\n",
    "df_clean = pd.read_pickle(dataset_path)\n",
    "df_subset = df_clean.iloc[inds]\n",
    "\n",
    "# subset according to criteria\n",
    "if genre is not None:\n",
    "    ind_genre = df_subset[\"genre\"] == genre\n",
    "    embeddings_subset = embeddings_subset[ind_genre]\n",
    "    df_subset = df_subset[ind_genre]\n",
    "    \n",
    "if danceability:\n",
    "    if danceability >= 0:\n",
    "        _ind = df_subset[\"danceability\"] > song_metadata[\"danceability\"]\n",
    "    else:\n",
    "        _ind = df_subset[\"danceability\"] < song_metadata[\"danceability\"]\n",
    "    embeddings_subset = embeddings_subset[_ind]\n",
    "    df_subset = df_subset[_ind]\n",
    "    \n",
    "# TODO other criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "# compute scores\n",
    "if affinity == \"cosine\":\n",
    "    scores = cosine_distances(query_embed[np.newaxis, :], embeddings_subset)[0]\n",
    "elif affinity == \"euclidean\":\n",
    "    scores = euclidean_distances(query_embed[np.newaxis, :], embeddings_subset)[0]\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5227248\n",
      "Genre: country Artist: Maren Morris SongName: Rich\n",
      "Lyrics: La-a-a-a-a-di-da. La-a-a-a-a-di-da. If I had a dollar every time that I swore you off. And a twenty every time that i picked up when you called. And a crisp new Benjamin for when you're here then gone\n",
      "*****\n",
      "Score: 0.530687\n",
      "Genre: country Artist: Luke Bryan SongName: Buzzkill\n",
      "Lyrics: Baby you're a buzzkill(x2). . We had a good thing but that was in the past tense. Since it went bad then you haven't been back since. You said I changed but really I never did. I just really stopped c\n",
      "*****\n",
      "Score: 0.5381939\n",
      "Genre: country Artist: Sam Hunt SongName: House Party\n",
      "Lyrics: You're on the couch, blowing up my phone. You don't want to come out, but you don't want to be alone. It don't take but two to have a little soiree. If you're in the mood, sit tight right where you ar\n",
      "*****\n",
      "Score: 0.5396657\n",
      "Genre: country Artist: Old Dominion SongName: Snapback\n",
      "Lyrics: Strictly outta curiosity. What would happen if you got with me?. Kissin' you would hit the spot with me. Come on skip a couple rocks with me. Give me any of your heart tonight. Ain't no reason that we\n",
      "*****\n",
      "Score: 0.55051494\n",
      "Genre: country Artist: Rascal Flatts SongName: I Like The Sound Of That\n",
      "Lyrics: I love hearing that shower turn on. Bet there's nothing but a towel on you. You sing along with some Timberlake bumping. But he ain't got nothing on you. I don't wanna hear the coffee pouring. A goodb\n",
      "*****\n",
      "Score: 0.5667282\n",
      "Genre: country Artist: Kelsea Ballerini SongName: Love Me Like You Mean It\n",
      "Lyrics: Oh hey, boy with your hat back.... Mmm, I kinda like that. If you wanna walk my way. Imma shoot you straight up. Show me what you're made of. I don't have time to waste on the boys. That are playing t\n",
      "*****\n",
      "Score: 0.56937325\n",
      "Genre: country Artist: Sam Hunt SongName: Drinkin' Too Much\n",
      "Lyrics: Pour a drink and take a sip of it. Feelin' like a hypocrite. Couple more and I won't give a shit. I never used to talk, I never used to talk like this. I’m sorry I named the album ‘Montevallo’. And I’\n",
      "*****\n",
      "Score: 0.5846478\n",
      "Genre: country Artist: Sam Hunt SongName: Leave The Night On\n",
      "Lyrics: They roll the sidewalks in this town, all up after the sun goes down. They say nothin' good happens here when midnight rolls around. But layin' down would be in vain, I can't sleep with you on my brai\n",
      "*****\n",
      "Score: 0.5996021\n",
      "Genre: country Artist: Sam Hunt SongName: Take Your Time\n",
      "Lyrics: I don't know if you were looking at me or not. You probably smile like that all the time. And I don't mean to bother you but. I couldn't just walk by. And not say hi. And I know your name. Cause every\n",
      "*****\n",
      "Score: 0.6116133\n",
      "Genre: country Artist: Shania Twain SongName: That Don't Impress Me Much\n",
      "Lyrics: Ow. Uh-huh, yeah, yeah. I've known a few guys who thought they were pretty smart. But you've got being right down to an art. You think you're a genius, you drive me up the wall. You're a regular origi\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "max_len = 200  # for printing lyrics\n",
    "\n",
    "topk = scores.argsort()[:K]\n",
    "for i in topk:\n",
    "    print(\"Score:\", scores[i])\n",
    "    print('Genre:',df_subset['genre'][i],'Artist:',df_subset['artist'][i],'SongName:',df_subset['song_name'][i])\n",
    "    print(\"Lyrics:\", df_subset['lyrics'][i][:max_len])\n",
    "    print('*****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
