{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 24 11:56:56 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    55W / 300W |  11265MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-task training\n",
    "\n",
    "Inspired by this notebook: https://colab.research.google.com/github/zphang/zphang.github.io/blob/master/files/notebooks/Multi_task_Training_with_Transformers_NLP.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import torch\n",
    "# print(tf.__version__)\n",
    "# print(torch.__version__)\n",
    "# !pip install pandas==1.1.4\n",
    "# !pip install tensorflow==2.4.1\n",
    "# !pip install torch==1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and define utility functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, ClassLabel, load_metric\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "\n",
    "def create_datasets(tokenized_lyrics, feature, n=None, verbose=True, n_class=1, max_val=1):\n",
    "    \"\"\"\n",
    "    n_class : if provided, quantize to this many classes with equal amount of per class\n",
    "    n : to subset for testing purposes\n",
    "    \"\"\"\n",
    "    lyrics_lab = tokenized_lyrics.copy()\n",
    "    \n",
    "    if n_class > 1:\n",
    "        edges = histedges_equalN(train[feature].values, n_class, max_val=max_val)\n",
    "        if verbose:\n",
    "            print(edges)\n",
    "        lyrics_lab[\"train\"] = lyrics_lab[\"train\"].add_column(\"labels\", quantize_feature(train[feature], edges))\n",
    "        lyrics_lab[\"validation\"] = lyrics_lab[\"validation\"].add_column(\"labels\", quantize_feature(val[feature], edges))\n",
    "        lyrics_lab[\"test\"] = lyrics_lab[\"test\"].add_column(\"labels\", quantize_feature(test[feature], edges))\n",
    "    else:\n",
    "        lyrics_lab[\"train\"] = lyrics_lab[\"train\"].add_column(\"labels\", train[feature])\n",
    "        lyrics_lab[\"validation\"] = lyrics_lab[\"validation\"].add_column(\"labels\", val[feature])\n",
    "        lyrics_lab[\"test\"] = lyrics_lab[\"test\"].add_column(\"labels\", test[feature])\n",
    "    if verbose:\n",
    "        print(lyrics_lab)\n",
    "    \n",
    "    if n is not None:\n",
    "        lyrics_lab[\"train\"] = lyrics_lab[\"train\"].shuffle(seed=seed).select(range(n)) \n",
    "        lyrics_lab[\"validation\"] = lyrics_lab[\"validation\"].shuffle(seed=seed).select(range(n)) \n",
    "        lyrics_lab[\"test\"] = lyrics_lab[\"test\"].shuffle(seed=seed).select(range(n)) \n",
    "    \n",
    "    if verbose:\n",
    "        print(lyrics_lab[\"train\"])\n",
    "        print(lyrics_lab[\"validation\"])\n",
    "        print(lyrics_lab[\"test\"])\n",
    "            \n",
    "    return lyrics_lab\n",
    "\n",
    "\n",
    "def quantize_feature(values, edges):\n",
    "    labels = values.copy().astype(np.int)\n",
    "    for i, _edge in enumerate(edges[:-1]):\n",
    "        if i == 0:\n",
    "            mask = values < edges[i+1]\n",
    "        else:\n",
    "            mask = np.logical_and(values >= edges[i], values < edges[i+1])\n",
    "        labels[mask] = i\n",
    "    return labels\n",
    "\n",
    "\n",
    "def histedges_equalN(x, nbin, max_val=None):\n",
    "    # https://stackoverflow.com/a/39419049\n",
    "    npt = len(x)\n",
    "    edges = np.interp(np.linspace(0, npt, nbin + 1), np.arange(npt), np.sort(x))\n",
    "    if max_val:\n",
    "        edges[-1] = max_val\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our base model for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"sentence-transformers/all-mpnet-base-v2\"    # 418 MB, 384 max length\n",
    "# model_str = \"sentence-transformers/all-distilroberta-v1\"   # 292 MB, 512 max length\n",
    "# model_str = \"sentence-transformers/all-MiniLM-L6-v2\"       # 80 MB, 256 max length\n",
    "# model_str = \"sentence-transformers/all-MiniLM-L12-v2\"       # 118 MB, 256 max length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) load and create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15863, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>explicit</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>release_year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3e9HZxeyfWwjeyPAMmWSSQ</th>\n",
       "      <td>Thought I'd end up with Sean. But he wasn't a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22900</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>-5.634</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.412</td>\n",
       "      <td>106.966</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>dance pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5p7ujcrUXASCNwRaWNHR1C</th>\n",
       "      <td>Found you when your heart was broke. I filled ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Without Me</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29700</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>-7.050</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.533</td>\n",
       "      <td>136.041</td>\n",
       "      <td>2018</td>\n",
       "      <td>Halsey</td>\n",
       "      <td>dance pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2xLMifQCjDGFmkHkpNLD9h</th>\n",
       "      <td>Astro, yeah. Sun is down, freezin' cold. That'...</td>\n",
       "      <td>1</td>\n",
       "      <td>SICKO MODE</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>-3.714</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.446</td>\n",
       "      <td>155.008</td>\n",
       "      <td>2018</td>\n",
       "      <td>Travis Scott</td>\n",
       "      <td>hip-hop/rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1rqqCSm0Qe4I9rUvWncaom</th>\n",
       "      <td>High, high hopes. Had to have high, high hopes...</td>\n",
       "      <td>0</td>\n",
       "      <td>High Hopes</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19300</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>-2.729</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.681</td>\n",
       "      <td>82.014</td>\n",
       "      <td>2018</td>\n",
       "      <td>Panic! At The Disco</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0bYg9bo50gSsH3LtXe2SQn</th>\n",
       "      <td>I-I-I don't want a lot for Christmas. There is...</td>\n",
       "      <td>0</td>\n",
       "      <td>All I Want for Christmas Is You</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16400</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>-7.462</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.346</td>\n",
       "      <td>150.277</td>\n",
       "      <td>1994</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>dance pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   lyrics  \\\n",
       "song_id                                                                     \n",
       "3e9HZxeyfWwjeyPAMmWSSQ  Thought I'd end up with Sean. But he wasn't a ...   \n",
       "5p7ujcrUXASCNwRaWNHR1C  Found you when your heart was broke. I filled ...   \n",
       "2xLMifQCjDGFmkHkpNLD9h  Astro, yeah. Sun is down, freezin' cold. That'...   \n",
       "1rqqCSm0Qe4I9rUvWncaom  High, high hopes. Had to have high, high hopes...   \n",
       "0bYg9bo50gSsH3LtXe2SQn  I-I-I don't want a lot for Christmas. There is...   \n",
       "\n",
       "                        explicit                        song_name  \\\n",
       "song_id                                                             \n",
       "3e9HZxeyfWwjeyPAMmWSSQ         1                    thank u, next   \n",
       "5p7ujcrUXASCNwRaWNHR1C         1                       Without Me   \n",
       "2xLMifQCjDGFmkHkpNLD9h         1                       SICKO MODE   \n",
       "1rqqCSm0Qe4I9rUvWncaom         0                       High Hopes   \n",
       "0bYg9bo50gSsH3LtXe2SQn         0  All I Want for Christmas Is You   \n",
       "\n",
       "                        song_popularity  mode  acousticness  danceability  \\\n",
       "song_id                                                                     \n",
       "3e9HZxeyfWwjeyPAMmWSSQ               86     1       0.22900         0.717   \n",
       "5p7ujcrUXASCNwRaWNHR1C               87     1       0.29700         0.752   \n",
       "2xLMifQCjDGFmkHkpNLD9h               85     1       0.00513         0.834   \n",
       "1rqqCSm0Qe4I9rUvWncaom               86     1       0.19300         0.579   \n",
       "0bYg9bo50gSsH3LtXe2SQn               63     1       0.16400         0.335   \n",
       "\n",
       "                        energy  instrumentalness  liveness  loudness  \\\n",
       "song_id                                                                \n",
       "3e9HZxeyfWwjeyPAMmWSSQ   0.653          0.000000    0.1010    -5.634   \n",
       "5p7ujcrUXASCNwRaWNHR1C   0.488          0.000009    0.0936    -7.050   \n",
       "2xLMifQCjDGFmkHkpNLD9h   0.730          0.000000    0.1240    -3.714   \n",
       "1rqqCSm0Qe4I9rUvWncaom   0.904          0.000000    0.0640    -2.729   \n",
       "0bYg9bo50gSsH3LtXe2SQn   0.625          0.000000    0.0708    -7.462   \n",
       "\n",
       "                        speechiness  valence    tempo  release_year  \\\n",
       "song_id                                                               \n",
       "3e9HZxeyfWwjeyPAMmWSSQ       0.0658    0.412  106.966          2019   \n",
       "5p7ujcrUXASCNwRaWNHR1C       0.0705    0.533  136.041          2018   \n",
       "2xLMifQCjDGFmkHkpNLD9h       0.2220    0.446  155.008          2018   \n",
       "1rqqCSm0Qe4I9rUvWncaom       0.0618    0.681   82.014          2018   \n",
       "0bYg9bo50gSsH3LtXe2SQn       0.0386    0.346  150.277          1994   \n",
       "\n",
       "                                     artist        genre  \n",
       "song_id                                                   \n",
       "3e9HZxeyfWwjeyPAMmWSSQ        Ariana Grande    dance pop  \n",
       "5p7ujcrUXASCNwRaWNHR1C               Halsey    dance pop  \n",
       "2xLMifQCjDGFmkHkpNLD9h         Travis Scott  hip-hop/rap  \n",
       "1rqqCSm0Qe4I9rUvWncaom  Panic! At The Disco         rock  \n",
       "0bYg9bo50gSsH3LtXe2SQn         Mariah Carey    dance pop  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load original dataframe\n",
    "df_clean = pd.read_pickle('df_clean_v4_14122021_py35.pkl')\n",
    "print(df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11104, 17)\n",
      "(7931, 17)\n",
      "(7932, 17)\n"
     ]
    }
   ],
   "source": [
    "# train, validation, test split\n",
    "seed = 11\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "train, _eval = train_test_split(df_clean, test_size=val_size + test_size, random_state=seed)\n",
    "val, test = train_test_split(df_clean, test_size=test_size / (val_size + test_size), random_state=seed)\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 11104\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 7931\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 7932\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# create a DatasetDict as expected by Hugging Face\n",
    "lyrics = DatasetDict()\n",
    "\n",
    "# arguments expected by forward: https://github.com/huggingface/transformers/blob/9aeacb58bab321bc21c24bbdf7a24efdccb1d426/src/transformers/modeling_bert.py#L1313\n",
    "lyrics[\"train\"] = Dataset.from_dict({\"text\": list(train[\"lyrics\"])})\n",
    "lyrics[\"validation\"] = Dataset.from_dict({\"text\": list(val[\"lyrics\"])})\n",
    "lyrics[\"test\"] = Dataset.from_dict({\"text\": list(test[\"lyrics\"])})\n",
    "\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cb7caf016c49848acee656f320a984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108257dacd354bc6a8ec1e29e6df2de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6471f73c24a4492ea2d77bf0dba43857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f92acb9345494985b9ae16c213a0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d7c7b086074ff2b2879a30f0c2935f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372b529a3fb04ab2b0949e37d9df91f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89668947b877498faf7da4ecef23e4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_str, use_fast=True)\n",
    "    \n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_lyrics = lyrics.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e299003444cf478faeccb93b8f9f2094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ec29b86b114ace86e0a216fefe50ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c13e4664af744e1b4fcfd764cba6c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'labels': ClassLabel(num_classes=8, names=['acoustic/folk', 'country', 'dance pop', 'hip-hop/rap', 'pop', 'r&b', 'rock', 'soul/disco'], names_file=None, id=None)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create genre dataset\n",
    "labels_lst = sorted(list(set(df_clean[\"genre\"])))\n",
    "labels = ClassLabel(names=labels_lst)\n",
    "genre_dataset = tokenized_lyrics.copy()\n",
    "genre_dataset[\"train\"] = genre_dataset[\"train\"].add_column(\"labels\", labels.str2int(train[\"genre\"]))\n",
    "genre_dataset[\"validation\"] = genre_dataset[\"validation\"].add_column(\"labels\", labels.str2int(val[\"genre\"]))\n",
    "genre_dataset[\"test\"] = genre_dataset[\"test\"].add_column(\"labels\", labels.str2int(test[\"genre\"]))\n",
    "# cast to ClassLabel\n",
    "for _key in genre_dataset.keys():\n",
    "    new_features = genre_dataset[_key].features.copy()\n",
    "    new_features[\"labels\"] = labels\n",
    "    genre_dataset[_key] = genre_dataset[_key].cast(new_features)\n",
    "# check correct type\n",
    "genre_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrap Your Arms Around Me by KC & The Sunshine Band\n",
      "\n",
      "Lyrics : Wrap your arms around me. Come on, come on. Wrap your arms around me. Get it on, get it on. Wrap your arms around me. Come on, come on. Wrap your arms around me. Rock me all night long. Oh, don't waste a minute. Don't waste no time. Give right to it. Come on and be mine. Wrap your arms around me. Co\n",
      "Genre : soul/disco\n",
      "Valence : 1\n",
      "Danceability : 1\n",
      "Energy : 1\n"
     ]
    }
   ],
   "source": [
    "# create dataset for other metadata\n",
    "valence_dataset = create_datasets(tokenized_lyrics, feature=\"valence\", n_class=2, verbose=False)\n",
    "danceability_dataset = create_datasets(tokenized_lyrics, feature=\"danceability\", n_class=2, verbose=False)\n",
    "energy_dataset = create_datasets(tokenized_lyrics, feature=\"energy\", n_class=2, verbose=False)\n",
    "\n",
    "\n",
    "_id = 1\n",
    "\n",
    "print(f\"{train.iloc[_id]['song_name']} by {train.iloc[_id]['artist']}\\n\")\n",
    "print(f\"Lyrics : {valence_dataset['train'][_id]['text'][:300]}\")\n",
    "print(f\"Genre : {labels.int2str(genre_dataset['train'][_id]['labels'])}\")\n",
    "print(f\"Valence : {valence_dataset['train'][_id]['labels']}\")\n",
    "print(f\"Danceability : {danceability_dataset['train'][_id]['labels']}\")\n",
    "print(f\"Energy : {energy_dataset['train'][_id]['labels']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    \"genre\": genre_dataset,\n",
    "    \"valence\": valence_dataset,\n",
    "#     \"danceability\": danceability_dataset,\n",
    "#     \"energy\": energy_dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre train 11104 11104\n",
      "genre train 11104 11104\n",
      "genre validation 7931 7931\n",
      "genre validation 7931 7931\n",
      "genre test 7932 7932\n",
      "genre test 7932 7932\n",
      "valence train 11104 11104\n",
      "valence train 11104 11104\n",
      "valence validation 7931 7931\n",
      "valence validation 7931 7931\n",
      "valence test 7932 7932\n",
      "valence test 7932 7932\n"
     ]
    }
   ],
   "source": [
    "columns_dict = {\n",
    "    \"genre\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \"valence\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \"danceability\": ['input_ids', 'attention_mask', 'labels'],\n",
    "    \"energy\": ['input_ids', 'attention_mask', 'labels'],\n",
    "}\n",
    "\n",
    "\n",
    "features_dict = {}\n",
    "for task_name, dataset in dataset_dict.items():\n",
    "    features_dict[task_name] = {}\n",
    "    for phase, phase_dataset in dataset.items():\n",
    "#         features_dict[task_name][phase] = phase_dataset.map(\n",
    "#             convert_func_dict[task_name],\n",
    "#             batched=True,\n",
    "#             load_from_cache_file=False,\n",
    "#         )\n",
    "        features_dict[task_name][phase] = phase_dataset\n",
    "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))\n",
    "        features_dict[task_name][phase].set_format(\n",
    "            type=\"torch\", \n",
    "            columns=columns_dict[task_name],\n",
    "        )\n",
    "        print(task_name, phase, len(phase_dataset), len(features_dict[task_name][phase]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict[\"genre\"][\"train\"][\"labels\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) create multitask model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sentence-transformers/all-mpnet-base-v2 were not used when initializing MPNetForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNetForSequenceClassification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sentence-transformers/all-mpnet-base-v2 were not used when initializing MPNetForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNetForSequenceClassification\n"
     ]
    }
   ],
   "source": [
    "class MultitaskModel(transformers.PreTrainedModel):\n",
    "    def __init__(self, encoder, taskmodels_dict):\n",
    "        \"\"\"\n",
    "        Setting MultitaskModel up as a PretrainedModel allows us\n",
    "        to take better advantage of Trainer features\n",
    "        \"\"\"\n",
    "        super().__init__(transformers.PretrainedConfig())\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.taskmodels_dict = nn.ModuleDict(taskmodels_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, model_name, model_type_dict, model_config_dict):\n",
    "        \"\"\"\n",
    "        This creates a MultitaskModel using the model class and config objects\n",
    "        from single-task models. \n",
    "\n",
    "        We do this by creating each single-task model, and having them share\n",
    "        the same encoder transformer.\n",
    "        \"\"\"\n",
    "        shared_encoder = None\n",
    "        taskmodels_dict = {}\n",
    "        for task_name, model_type in model_type_dict.items():\n",
    "            model = model_type.from_pretrained(\n",
    "                model_name, \n",
    "                config=model_config_dict[task_name],\n",
    "            )\n",
    "            if shared_encoder is None:\n",
    "                shared_encoder = getattr(model, cls.get_encoder_attr_name(model))\n",
    "            else:\n",
    "                setattr(model, cls.get_encoder_attr_name(model), shared_encoder)\n",
    "            taskmodels_dict[task_name] = model\n",
    "        return cls(encoder=shared_encoder, taskmodels_dict=taskmodels_dict)\n",
    "\n",
    "    @classmethod\n",
    "    def get_encoder_attr_name(cls, model):\n",
    "        \"\"\"\n",
    "        The encoder transformer is named differently in each model \"architecture\".\n",
    "        This method lets us get the name of the encoder attribute\n",
    "        \"\"\"\n",
    "        model_class_name = model.__class__.__name__\n",
    "        print(model_class_name)\n",
    "        if model_class_name.startswith(\"Bert\"):\n",
    "            return \"bert\"\n",
    "        elif model_class_name.startswith(\"Roberta\"):\n",
    "            return \"roberta\"\n",
    "        elif model_class_name.startswith(\"Albert\"):\n",
    "            return \"albert\"\n",
    "        elif model_class_name.startswith(\"MPNet\"):\n",
    "            return \"mpnet\"\n",
    "        else:\n",
    "            raise KeyError(f\"Add support for new model {model_class_name}\")\n",
    "\n",
    "    def forward(self, task_name, **kwargs):\n",
    "        return self.taskmodels_dict[task_name](**kwargs)\n",
    "    \n",
    "multitask_model = MultitaskModel.create(\n",
    "    model_name=model_str,\n",
    "    model_type_dict={\n",
    "        \"genre\": transformers.AutoModelForSequenceClassification,\n",
    "        \"valence\": transformers.AutoModelForSequenceClassification\n",
    "    },\n",
    "    model_config_dict={\n",
    "        \"genre\": transformers.AutoConfig.from_pretrained(model_str, num_labels=len(labels_lst)),\n",
    "        \"valence\": transformers.AutoConfig.from_pretrained(model_str, num_labels=2)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694497280\n",
      "1694497280\n",
      "1694497280\n"
     ]
    }
   ],
   "source": [
    "# check use same encoder\n",
    "if \"mpnet\" in model_str:\n",
    "    print(multitask_model.encoder.embeddings.word_embeddings.weight.data_ptr())\n",
    "    for _key in multitask_model.taskmodels_dict.keys():\n",
    "        print(multitask_model.taskmodels_dict[_key].mpnet.embeddings.word_embeddings.weight.data_ptr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) preparing multi-task data loader\n",
    "https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function typing.NewType.<locals>.new_type(x)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataCollator    # indeed a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers.data.data_collator import DataCollator, InputDataClass, DefaultDataCollator\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from typing import List, Union, Dict\n",
    "\n",
    "\n",
    "# class NLPDataCollator(DataCollator):\n",
    "class NLPDataCollator(DefaultDataCollator):\n",
    "    \"\"\"\n",
    "    Extending the existing DataCollator to work with NLP dataset batches\n",
    "    \"\"\"\n",
    "    def collate_batch(self, features):\n",
    "        first = features[0]\n",
    "        if isinstance(first, dict):\n",
    "            # NLP data sets current works presents features as lists of dictionary\n",
    "            # (one per example), so we  will adapt the collate_batch logic for that\n",
    "            if \"labels\" in first and first[\"labels\"] is not None:\n",
    "                if first[\"labels\"].dtype == torch.int64:\n",
    "                    labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
    "                else:\n",
    "                    labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.float)\n",
    "                batch = {\"labels\": labels}\n",
    "            for k, v in first.items():\n",
    "                if k != \"labels\" and v is not None and not isinstance(v, str):\n",
    "                    batch[k] = torch.stack([f[k] for f in features])\n",
    "            return batch\n",
    "        else:\n",
    "            # otherwise, revert to using the default collate_batch\n",
    "            return DefaultDataCollator().collate_batch(features)\n",
    "\n",
    "\n",
    "class StrIgnoreDevice(str):\n",
    "    \"\"\"\n",
    "    This is a hack. The Trainer is going call .to(device) on every input\n",
    "    value, but we need to pass in an additional `task_name` string.\n",
    "    This prevents it from throwing an error\n",
    "    \"\"\"\n",
    "    def to(self, device):\n",
    "        return self\n",
    "\n",
    "\n",
    "class DataLoaderWithTaskname:\n",
    "    \"\"\"\n",
    "    Wrapper around a DataLoader to also yield a task name\n",
    "    \"\"\"\n",
    "    def __init__(self, task_name, data_loader):\n",
    "        self.task_name = task_name\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "        self.batch_size = data_loader.batch_size\n",
    "        self.dataset = data_loader.dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            batch[\"task_name\"] = StrIgnoreDevice(self.task_name)\n",
    "            yield batch\n",
    "\n",
    "\n",
    "class MultitaskDataloader:\n",
    "    \"\"\"\n",
    "    Data loader that combines and samples from multiple single-task\n",
    "    data loaders.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader_dict):\n",
    "        self.dataloader_dict = dataloader_dict\n",
    "        self.num_batches_dict = {\n",
    "            task_name: len(dataloader) \n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        self.task_name_list = list(self.dataloader_dict)\n",
    "        self.dataset = [None] * sum(\n",
    "            len(dataloader.dataset) \n",
    "            for dataloader in self.dataloader_dict.values()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.num_batches_dict.values())\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        For each batch, sample a task, and yield a batch from the respective\n",
    "        task Dataloader.\n",
    "\n",
    "        We use size-proportional sampling, but you could easily modify this\n",
    "        to sample from some-other distribution.\n",
    "        \"\"\"\n",
    "        task_choice_list = []\n",
    "        for i, task_name in enumerate(self.task_name_list):\n",
    "            task_choice_list += [i] * self.num_batches_dict[task_name]\n",
    "        task_choice_list = np.array(task_choice_list)\n",
    "        np.random.shuffle(task_choice_list)\n",
    "        dataloader_iter_dict = {\n",
    "            task_name: iter(dataloader) \n",
    "            for task_name, dataloader in self.dataloader_dict.items()\n",
    "        }\n",
    "        for task_choice in task_choice_list:\n",
    "            task_name = self.task_name_list[task_choice]\n",
    "            yield next(dataloader_iter_dict[task_name])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) preparing multi-task Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskTrainer(transformers.Trainer):\n",
    "\n",
    "    def get_single_train_dataloader(self, task_name, train_dataset):\n",
    "        \"\"\"\n",
    "        Create a single-task data loader that also yields task names\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "#         if is_tpu_available():\n",
    "#             train_sampler = get_tpu_sampler(train_dataset)\n",
    "#         else:\n",
    "        train_sampler = (\n",
    "            RandomSampler(train_dataset)\n",
    "            if self.args.local_rank == -1\n",
    "            else DistributedSampler(train_dataset)\n",
    "        )\n",
    "\n",
    "        data_loader = DataLoaderWithTaskname(\n",
    "            task_name=task_name,\n",
    "            data_loader=DataLoader(\n",
    "              train_dataset,\n",
    "              batch_size=self.args.train_batch_size,\n",
    "              sampler=train_sampler,\n",
    "              collate_fn=self.data_collator.collate_batch,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "#         if is_tpu_available():\n",
    "#             data_loader = pl.ParallelLoader(\n",
    "#                 data_loader, [self.args.device]\n",
    "#             ).per_device_loader(self.args.device)\n",
    "        return data_loader\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a MultitaskDataloader, which is not actually a Dataloader\n",
    "        but an iterable that returns a generator that samples from each \n",
    "        task Dataloader\n",
    "        \"\"\"\n",
    "        return MultitaskDataloader({\n",
    "            task_name: self.get_single_train_dataloader(task_name, task_dataset)\n",
    "            for task_name, task_dataset in self.train_dataset.items()\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 22208\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='94' max='8328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  94/8328 00:26 < 40:03, 3.43 it/s, Epoch 0.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-82bfe2bf2382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 if (\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = {\n",
    "    task_name: dataset[\"train\"] \n",
    "    for task_name, dataset in dataset_dict.items()\n",
    "}\n",
    "trainer = MultitaskTrainer(\n",
    "    model=multitask_model,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=\"genre_and_valence_fine_tuning\",\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=1e-5,\n",
    "        do_train=True,\n",
    "        num_train_epochs=3,\n",
    "        # Adjust batch size if this doesn't fit on the Colab GPU\n",
    "        per_device_train_batch_size=8,  \n",
    "        save_steps=3000,\n",
    "    ),\n",
    "    data_collator=NLPDataCollator(),\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
